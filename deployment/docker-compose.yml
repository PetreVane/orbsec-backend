version: '3.7'

services:

  # The 'setup' service runs a one-off script which initializes the
  # 'logstash_internal' and 'kibana_system' users inside Elasticsearch with the
  # values of the passwords defined in the '.env' file.
  #
  # This task is only performed during the *initial* startup of the stack. On all
  # subsequent runs, the service simply returns immediately, without performing
  # any modification to existing users.
  setup:
    build:
      context: setup/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    init: true
    volumes:
      - setup:/state:Z
    environment:
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    networks:
      - orbsec_backend

# Starting Kafka - Confluent containers
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

    networks:
      orbsec_backend:
        aliases:
          - "zookeeper"

  broker:
    image: confluentinc/cp-server:7.0.1
    hostname: broker
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'

    networks:
      orbsec_backend:
        aliases:
          - "broker"

  schema-registry:
    image: confluentinc/cp-schema-registry:7.0.1
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - broker
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

    networks:
      orbsec_backend:
        aliases:
          - "schema-registry"

  control-center:
      image: confluentinc/cp-enterprise-control-center:7.0.1
      hostname: control-center
      container_name: control-center
      depends_on:
        - broker
        - schema-registry

      ports:
        - "9021:9021"
      environment:
        CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
        CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'connect:8083'
        CONTROL_CENTER_KSQL_KSQLDB1_URL: "http://ksqldb-server:8088"
        CONTROL_CENTER_KSQL_KSQLDB1_ADVERTISED_URL: "http://localhost:8088"
        CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
        CONTROL_CENTER_REPLICATION_FACTOR: 1
        CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
        CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
        CONFLUENT_METRICS_TOPIC_REPLICATION: 1
        PORT: 9021

      networks:
        orbsec_backend:
          aliases:
            - "control-center"

  rest-proxy:
      image: confluentinc/cp-kafka-rest:7.0.1
      depends_on:
        - broker
        - schema-registry
      ports:
        - 8082:8082
      hostname: rest-proxy
      container_name: rest-proxy
      environment:
        KAFKA_REST_HOST_NAME: rest-proxy
        KAFKA_REST_BOOTSTRAP_SERVERS: 'broker:29092'
        KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
        KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'

      networks:
        orbsec_backend:
          aliases:
            - "rest-proxy"


# Starting Elasticsearch containers
  elasticsearch:
    build:
      context: elasticsearch/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,z
      - elasticsearch:/usr/share/elasticsearch/data:z
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: -Xmx256m -Xms256m
      # Bootstrap password.
      # Used to initialize the keystore during the initial startup of
      # Elasticsearch. Ignored on subsequent runs.
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      - orbsec_backend

  logstash:
    build:
      context: logstash/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
    ports:
      - "5044:5044"
      - "5001:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: -Xmx256m -Xms256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    networks:
      - orbsec_backend
    depends_on:
      - elasticsearch

  kibana:
    build:
      context: kibana/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
    ports:
      - "5601:5601"
    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    networks:
      - orbsec_backend
    depends_on:
      - elasticsearch

  zipkin:
    image: openzipkin/zipkin
    container_name: zipkin
    depends_on:
      - elasticsearch
    environment:
      - STORAGE_TYPE=elasticsearch
      - ES_HOSTS=elasticsearch:9300
      - KAFKA_BOOTSTRAP_SERVERS=broker:9092
      - COLLECTOR_KAFKA_ENABLED=true
      - KAFKA_GROUP_ID=zipkin-server
      - ZIPKIN_COLLECTOR_KAFKA_TOPIC=zipkin

    ports:
      - "9411:9411"
    networks:
      orbsec_backend:
        aliases:
          - "zipkin"

# Starting cache and database containers
  redis:
    image: redis:alpine
    container_name: redis
    hostname: redis

    ports:
      - 6379:6379

    networks:
      orbsec_backend:
        aliases:
          - "redis"

  license-database:
    image: postgres:latest
    ports:
      - "5433:5432"

    environment:
      POSTGRES_USER: "postgres"
      POSTGRES_PASSWORD: "postgres"
      POSTGRES_DB: "orbsec_dev_license"

    volumes:
        - ./database-containers/init-license-db.sql:/docker-entrypoint-initdb.d/1-init.sql
        - ./database-containers/data-license-db.sql:/docker-entrypoint-initdb.d/2-data.sql

    networks:
      orbsec_backend:
        aliases:
          - "license-database"

    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  organization-database:
    image: postgres:latest
    ports:
      - "5432:5432"

    environment:
      POSTGRES_USER: "postgres"
      POSTGRES_PASSWORD: "postgres"
      POSTGRES_DB: "orbsec_dev_organization"

    volumes:
      - ./database-containers/init-organization-db.sql:/docker-entrypoint-initdb.d/1-init.sql
      - ./database-containers/data-organization-db.sql:/docker-entrypoint-initdb.d/2-data.sql

    networks:
      orbsec_backend:
        aliases:
          - "organization-database"

    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5


networks:
  orbsec_backend:
    driver: bridge

volumes:
  setup:
  elasticsearch:
